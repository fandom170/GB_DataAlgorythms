{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rental-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "effective-immunology",
   "metadata": {},
   "source": [
    "## Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpha-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "classification_data, classification_labels = make_classification(n_features=2, n_informative=2, \n",
    "                                                                 n_classes=2, n_redundant=0,\n",
    "                                                                 n_clusters_per_class=1, random_state=5, n_samples=1000)\n",
    "#classification_data, classification_labels = make_circles(n_samples=30, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "polish-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "#исходные данные для регресии\n",
    "regression_data, regression_labels = make_regression(n_features=2, \n",
    "                                                     n_informative=2, \n",
    "                                                     n_targets = 1,\n",
    "                                                     noise = 1.25,\n",
    "                                                     random_state=6, \n",
    "                                                     n_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-lloyd",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-democrat",
   "metadata": {},
   "source": [
    "**1. В коде из методички реализуйте один или несколько из критериев останова (количество листьев, количество используемых признаков, глубина дерева и т.д.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-greensboro",
   "metadata": {},
   "source": [
    "### Реализация дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rapid-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "\n",
    "    # Если лист, то выводим его прогноз\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Прогноз:\", node.prediction)\n",
    "        return\n",
    "\n",
    "    # Выведем значение индекса и порога на этом узле\n",
    "    print(spacing + 'Индекс', str(node.index), '<=', str(node.t))\n",
    "\n",
    "    # Рекурсионный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Рекурсионный вызов функции на отрицательном поддереве\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varied-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет прироста\n",
    "\n",
    "def gain(left_labels, right_labels, root_gini):\n",
    "\n",
    "    # доля выборки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return root_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "postal-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет критерия Джини\n",
    "\n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prerequisite-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node: \n",
    "    \"\"\"Clss implements single tree node\"\"\"\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "senior-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verified-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ranging-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dying-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-suggestion",
   "metadata": {},
   "source": [
    "Разделение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vocational-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(classification_data, \n",
    "                                                                    classification_labels, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tough-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-april",
   "metadata": {},
   "source": [
    "min_samples_leaf - уже было представлено в коде. Таким образм для реаизации этого разграничения достаточно было раскомментировать соответсвующие строки кода в find_best_split функции.  \n",
    "max_depth - в качестве вкличины глубины бралось количество узлов не считая RootNode. соответсвенно, дерево с глубиной 0 в данной реализации имеет только один Root Node.  \n",
    "min_samples_split - количество узлов при котором разрешен дальнейший сплит."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-failure",
   "metadata": {},
   "source": [
    "Функции, которые были изменены в рамках этой задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "induced-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels, min_samples_leaf):\n",
    "    \"\"\"min samples leaf has been added as parameter\n",
    "    \"\"\"\n",
    "    root_gini = gini(labels)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_labels, false_labels, root_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interim-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "# Добавлены новые параметры к вызову главной функции для условий необходимых при выполнении ДЗ\n",
    "def build_tree(data, labels, depth = 0 ,min_samples_leaf = 1, min_samples_split=2):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # используем глобальную переменную для передачи параметра максимальной глубины дерева\n",
    "    global tree_max_depth\n",
    "    #print(depth)\n",
    "    # Прекращение рекурсии при достижении максимальной глубины дерева \n",
    "    # или если длина массива с данными меньше определенной величины min_samples_split\n",
    "    if (depth < tree_max_depth) and (data.shape[0] > min_samples_split):\n",
    "        gain, t, index = find_best_split(data, labels, min_samples_leaf)\n",
    "    #--------------------------------------------\n",
    "        \n",
    "        #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "        if gain == 0:\n",
    "            return Leaf(data, labels)\n",
    "    \n",
    "\n",
    "        true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "        depth += 1\n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = build_tree(true_data, true_labels, depth, min_samples_leaf, min_samples_split)\n",
    "\n",
    "        false_branch = build_tree(false_data, false_labels, depth, min_samples_leaf, min_samples_split)\n",
    "    \n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    # returning leaf when reaches max depth\n",
    "    return Leaf(data, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-powder",
   "metadata": {},
   "source": [
    "Проверка работы доработанного дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "following-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "official-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(X_train, y_train, min_samples_leaf=1, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "christian-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict(X_train, my_tree)\n",
    "y_pred_test = predict(X_test, my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adolescent-vector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.42857142857143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = accuracy_metric(y_train, y_pred_train)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "surprised-learning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.66666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = accuracy_metric(y_test, y_pred_test)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "christian-provider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0 <= 0.11262584256582331\n",
      "--> True:\n",
      "  Индекс 1 <= -1.328019471718083\n",
      "  --> True:\n",
      "    Индекс 1 <= -1.655622580730638\n",
      "    --> True:\n",
      "      Индекс 0 <= -1.3947317874033134\n",
      "      --> True:\n",
      "        Прогноз: 1\n",
      "      --> False:\n",
      "        Индекс 0 <= -0.8728986138474495\n",
      "        --> True:\n",
      "          Прогноз: 0\n",
      "        --> False:\n",
      "          Прогноз: 0\n",
      "    --> False:\n",
      "      Индекс 0 <= -0.40624967911194587\n",
      "      --> True:\n",
      "        Индекс 1 <= -1.5754574590319361\n",
      "        --> True:\n",
      "          Прогноз: 1\n",
      "        --> False:\n",
      "          Прогноз: 0\n",
      "      --> False:\n",
      "        Индекс 1 <= -1.5651256447341462\n",
      "        --> True:\n",
      "          Прогноз: 0\n",
      "        --> False:\n",
      "          Прогноз: 1\n",
      "  --> False:\n",
      "    Прогноз: 0\n",
      "--> False:\n",
      "  Индекс 1 <= -1.4518330557811816\n",
      "  --> True:\n",
      "    Прогноз: 0\n",
      "  --> False:\n",
      "    Индекс 1 <= -0.9250008192636487\n",
      "    --> True:\n",
      "      Индекс 1 <= -0.9253697821973186\n",
      "      --> True:\n",
      "        Индекс 1 <= -1.0626111898166881\n",
      "        --> True:\n",
      "          Прогноз: 1\n",
      "        --> False:\n",
      "          Прогноз: 1\n",
      "      --> False:\n",
      "        Прогноз: 0\n",
      "    --> False:\n",
      "      Прогноз: 1\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-length",
   "metadata": {},
   "source": [
    "При установке min_samples_leaf > 35 дерево вырождается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-rapid",
   "metadata": {},
   "source": [
    "Maximum number of leaf nodes  \n",
    "Maximum features to consider for a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dominant-simple",
   "metadata": {},
   "source": [
    "**2. *Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-geneva",
   "metadata": {},
   "source": [
    "Доработанная функция.  \n",
    "Критерий Джини заменен на расчет дисперсии приведенный в отдлельной функции.  \n",
    "Результат рассчитывается, как сумма дисперсий для следующих ветвей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bigger-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доработанная функция расчета дисперсии\n",
    "\n",
    "def variance_regr(left_labels, right_labels, root_variance):\n",
    "\n",
    "    general_variance = (left_labels.shape[0] * variance(left_labels) + right_labels.shape[0] \n",
    "                        * variance(right_labels))/(left_labels.shape[0] + right_labels.shape[0])\n",
    "    #result = root_variance - general_variance\n",
    "    result = general_variance\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-sending",
   "metadata": {},
   "source": [
    "стандартный расчет дисперсии.  \n",
    "Может быть заменен встроенной функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sustained-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(labels):\n",
    "    # расчет дисперсии для переденного массива\n",
    "    branch_variance = (np.power((labels - labels.mean()), 2)).sum()/labels.shape[0]\n",
    "    # ну, или labels.var()  :)\n",
    "\n",
    "    return branch_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-entity",
   "metadata": {},
   "source": [
    "Класс содержит небольшие переименования, чтобы не пересекаться с предыдущим заданием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "purple-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доработанный класс терминального узла (листа)\n",
    "\n",
    "class Leaf_regr:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict_regr()\n",
    "        \n",
    "    def predict_regr(self):\n",
    "        #Найдем среднее по всем значениям и вернем его в качестве предсказания.\n",
    "        prediction = self.labels.mean()\n",
    "        return prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-edward",
   "metadata": {},
   "source": [
    "Доработанный best_split.  \n",
    "Адаптировано к дисперсии  \n",
    "Дополнительно добавлено ограничение глубины дерева из предыдущей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "convinced-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения. Изменение критерия gini на дисперсию вместе с переименованием переменных.\n",
    "\n",
    "def find_best_split_regr(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 5\n",
    "\n",
    "    root_variance = variance(labels)\n",
    "\n",
    "    best_variance = np.inf\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])        \n",
    "     \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split_regr(data, labels, index, t)\n",
    "\n",
    "            #  пропускаем разбиения, в которых в узле остается меньше определенного количество объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_variance = variance_regr(true_labels, false_labels, root_variance)\n",
    "                        \n",
    "            #  выбираем порог, на котором получается минимальная дисперсия\n",
    "            if current_variance < best_variance:                \n",
    "                best_variance, best_t, best_index = current_variance, t, index\n",
    "                #print(best_variance, best_t, best_index)\n",
    "    \n",
    "    #print(best_variance, best_t, best_index)\n",
    "    return best_variance, best_t, best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-occupation",
   "metadata": {},
   "source": [
    "Т.к. мы исключили критерий Джини, то имеет смысл оптимизировать разделение на ветви по величине дисперсии, а не по информационному критерию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "recovered-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree_regr(data, labels, depth = 0):\n",
    "    \n",
    "    global tree_max_depth_regr\n",
    "    global epsilon\n",
    "    \n",
    "    if (depth < tree_max_depth_regr):    \n",
    "        \n",
    "        variance, t, index = find_best_split_regr(data, labels)\n",
    "        #print(\"Current data\", variance, t, index)\n",
    "        \n",
    "        if variance == 0 or (variance == np.inf and t is None and index is None):\n",
    "            return Leaf_regr(data, labels)\n",
    "        \n",
    "        #print(\"split from build_tree\")\n",
    "        true_data, false_data, true_labels, false_labels = split_regr(data, labels, index, t)\n",
    "\n",
    "        # Рекурсивно строим два поддерева\n",
    "        #print(true_data.shape, true_labels.shape)\n",
    "        \n",
    "        depth += 1\n",
    "        \n",
    "        true_branch = build_tree_regr(true_data, true_labels, depth)\n",
    "    \n",
    "        false_branch = build_tree_regr(false_data, false_labels, depth)    \n",
    "     \n",
    "        # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    return Leaf_regr(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-fantasy",
   "metadata": {},
   "source": [
    "Изменено название класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eligible-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object_regr(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf_regr):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object_regr(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object_regr(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-armor",
   "metadata": {},
   "source": [
    "Изменено только название класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "centered-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_regr(data, tree):    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object_regr(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-edition",
   "metadata": {},
   "source": [
    "### Классы и функции без изменений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pleasant-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node: \n",
    "    \"\"\"Clss implements single tree node\"\"\"\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-mailman",
   "metadata": {},
   "source": [
    "Изменено только название функции для исключения пересечения с предыдущим заданием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pediatric-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле\n",
    "\n",
    "def split_regr(data, labels, column_index, t):\n",
    " \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-kruger",
   "metadata": {},
   "source": [
    "Функция расчета среднеквадратичной ошибки, как метрики для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "assured-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred):\n",
    "    \n",
    "    mse_value = (np.sum((y_pred - y)**2)) / y.shape[0]\n",
    "    \n",
    "    return mse_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-decision",
   "metadata": {},
   "source": [
    "### Проверка работы доработанного дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-block",
   "metadata": {},
   "source": [
    "Разделение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "structured-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(regression_data, \n",
    "                                                                    regression_labels, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-result",
   "metadata": {},
   "source": [
    "Глобальные переменные - ограничение параметров дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "coupled-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_max_depth_regr = 10\n",
    "epsilon = 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ignored-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_regr = build_tree_regr(X_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "secondary-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_regr = predict_regr(X_train_reg, my_tree_regr)\n",
    "y_pred_test_regr = predict_regr(X_test_reg, my_tree_regr)\n",
    "#y_pred_train_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-freedom",
   "metadata": {},
   "source": [
    "Сревнение величины ошибки для тренировочного и тестового датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "electronic-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651.3144590245006"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train = mse(y_train_reg, y_pred_train_regr)\n",
    "mse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "operational-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820.0182152431594"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = mse(y_test_reg, y_pred_test_regr)\n",
    "mse_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
